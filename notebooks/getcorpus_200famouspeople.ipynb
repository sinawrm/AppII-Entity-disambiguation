{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sinawrm/AppII-Entity-disambiguation/blob/main/notebooks/getcorpus_200famouspeople.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mmf1-l6eYH2A"
      },
      "outputs": [],
      "source": [
        "# Jupyter notebook to build the corpus data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ULSEKBZwYH2D",
        "outputId": "ec06c290-43db-4f75-c9bd-dae674caae2f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting wikipedia"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: You are using pip version 21.3.1; however, version 23.1.2 is available.\n",
            "You should consider upgrading via the 'C:\\Users\\sinaw\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip' command.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Using cached wikipedia-1.4.0.tar.gz (27 kB)\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Collecting beautifulsoup4\n",
            "  Using cached beautifulsoup4-4.12.2-py3-none-any.whl (142 kB)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in c:\\users\\sinaw\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from wikipedia) (2.27.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\sinaw\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (1.26.8)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\sinaw\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.0.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sinaw\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2021.10.8)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sinaw\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.3)\n",
            "Collecting soupsieve>1.2\n",
            "  Using cached soupsieve-2.4.1-py3-none-any.whl (36 kB)\n",
            "Building wheels for collected packages: wikipedia\n",
            "  Building wheel for wikipedia (setup.py): started\n",
            "  Building wheel for wikipedia (setup.py): finished with status 'done'\n",
            "  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11695 sha256=1bdbd3f8f333beea140c9d02f3484ac4c26513a0388ecea40793b823a70e2d2b\n",
            "  Stored in directory: c:\\users\\sinaw\\appdata\\local\\pip\\cache\\wheels\\c2\\46\\f4\\caa1bee71096d7b0cdca2f2a2af45cacf35c5760bee8f00948\n",
            "Successfully built wikipedia\n",
            "Installing collected packages: soupsieve, beautifulsoup4, wikipedia\n",
            "Successfully installed beautifulsoup4-4.12.2 soupsieve-2.4.1 wikipedia-1.4.0\n"
          ]
        }
      ],
      "source": [
        "! pip install wikipedia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0z44PfD2YH2F"
      },
      "outputs": [],
      "source": [
        "import wikipedia\n",
        "import csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m8Zj5LENYH2G"
      },
      "outputs": [],
      "source": [
        "# extract the names of 200 famous people from the csv-file\n",
        "\n",
        "names = []\n",
        "\n",
        "with open('famous200people.csv') as csvdatei:\n",
        "    csv_reader_object = csv.reader(csvdatei, delimiter=';')\n",
        "    for row in csv_reader_object:\n",
        "        names.append(row)\n",
        "    #    print(row)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "udDBXYm9YH2H"
      },
      "outputs": [],
      "source": [
        "# get summaries of the wikipedia articles of the 200 famous people in the list of names\n",
        "\n",
        "len_corpus=len(names) # length = 200\n",
        "text=[]\n",
        "\n",
        "for i in range(0, len_corpus):\n",
        "    top_article=wikipedia.search(names[i])[0]\n",
        "    summary = wikipedia.summary(top_article, auto_suggest=False)\n",
        "    text.append(summary)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9eiBYbygYH2H"
      },
      "outputs": [],
      "source": [
        "# add some ambiguity texts - same name other persons/ things\n",
        "amb_names_michaeljordan = ['Michael_B._Jordan','Michael_Jordan_(footballer)','Michael_Jordan_(offensive_lineman)']\n",
        "amb_names_emmawatson = ['Emma_Watson_(footballer)']\n",
        "amb_names_adele = ['Jan_Adele','Adele_Island_(Western_Australia)','Australian_steamer_Adele']\n",
        "amb_names_jkrowling = ['Bill_Rowling','Ian_Rowling','Reese_Rowling']\n",
        "\n",
        "\n",
        "ambiguity_names = amb_names_michaeljordan + amb_names_emmawatson + amb_names_adele + amb_names_jkrowling\n",
        "\n",
        "for i in range(0, len(ambiguity_names)):\n",
        "    am_name_sum=wikipedia.summary(ambiguity_names[i], auto_suggest=False)\n",
        "    text.append(am_name_sum)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_BRMc6AOYH2I"
      },
      "outputs": [],
      "source": [
        "# create empty txt-file\n",
        "file = open('corpus.txt', 'w')\n",
        "file.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YuQnqJvzYH2J"
      },
      "outputs": [],
      "source": [
        "# write wikipedia passages in corpus.txt file\n",
        "\n",
        "for line in text:\n",
        "    with open('corpus.txt', 'a', encoding=\"utf-8\") as f:\n",
        "        f.write(line)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}